"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7472],{519:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"prompts/evaluation","title":"Evaluation","description":"Judge outputs and iterate to better prompts.","source":"@site/docs/prompts/evaluation.md","sourceDirName":"prompts","slug":"/prompts/evaluation","permalink":"/docs/prompts/evaluation","draft":false,"unlisted":false,"editUrl":"https://github.com/llama-farm/llamafarm/tree/main/docs/website/docs/prompts/evaluation.md","tags":[],"version":"current","frontMatter":{"title":"Evaluation","sidebar_label":"Evaluation","slug":"/prompts/evaluation","toc_min_heading_level":2,"toc_max_heading_level":3},"sidebar":"tutorialSidebar","previous":{"title":"Templates","permalink":"/docs/prompts/templates"},"next":{"title":"Models","permalink":"/docs/models"}}');var i=n(4848),r=n(8453);const s={title:"Evaluation",sidebar_label:"Evaluation",slug:"/prompts/evaluation",toc_min_heading_level:2,toc_max_heading_level:3},o=void 0,l={},c=[{value:"Criteria",id:"criteria",level:2},{value:"A/B testing",id:"ab-testing",level:2},{value:"Automation",id:"automation",level:2}];function p(e){const t={code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"Judge outputs and iterate to better prompts."}),"\n",(0,i.jsx)(t.h2,{id:"criteria",children:"Criteria"}),"\n",(0,i.jsx)(t.p,{children:"Define objective metrics and rubrics. Example CLI usage:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'# Evaluate AI responses\nuv run python -m prompts.cli evaluate "AI is machine learning" \\\n  --query "What is AI?" \\\n  --criteria "accuracy,clarity,completeness" \\\n  --output-format detailed\n'})}),"\n",(0,i.jsx)(t.h2,{id:"ab-testing",children:"A/B testing"}),"\n",(0,i.jsx)(t.p,{children:"Compare prompt variants with the same inputs."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'# Create variant templates\ncp templates/basic/qa_basic.json templates/basic/qa_basic_v2.json\n\n# Run A/B\nuv run python -m prompts.cli execute "Explain machine learning" --template qa_basic > response_a.txt\nuv run python -m prompts.cli execute "Explain machine learning" --template qa_basic_v2 > response_b.txt\n\n# Evaluate both\nuv run python -m prompts.cli evaluate "$(cat response_a.txt)" \\\n  --query "Explain machine learning" \\\n  --criteria "clarity,completeness" \\\n  --output-format score > score_a.txt\nuv run python -m prompts.cli evaluate "$(cat response_b.txt)" \\\n  --query "Explain machine learning" \\\n  --criteria "clarity,completeness" \\\n  --output-format score > score_b.txt\n'})}),"\n",(0,i.jsx)(t.h2,{id:"automation",children:"Automation"}),"\n",(0,i.jsx)(t.p,{children:"Wire into CI with your preferred runner. Examples:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Validate templates and run evaluation on PRs"}),"\n",(0,i.jsx)(t.li,{children:"Fail builds on regression thresholds (e.g., clarity score drop)"}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var a=n(6540);const i={},r=a.createContext(i);function s(e){const t=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(r.Provider,{value:t},e.children)}}}]);